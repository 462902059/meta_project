{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96541549",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio===0.9.1 -f  https://download.pytorch.org/whl/torch_stable.html -i https://pypi.tuna.tsinghua.edu.cn/simple some-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ace39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pytorch/fairseq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f336252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./fairseq\n",
    "!pip uninstall numpy -q -y\n",
    "!pip install --editable ./ -q\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651768d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece -q\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1812708",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"http://dl.fbaipublicfiles.com/m2m_100/spm.128k.model\"\n",
    "!wget \"http://dl.fbaipublicfiles.com/m2m_100/data_dict.128k.txt\"\n",
    "!wget \"http://dl.fbaipublicfiles.com/m2m_100/model_dict.128k.txt\"\n",
    "!wget \"http://dl.fbaipublicfiles.com/m2m_100/language_pairs_small_models.txt\"\n",
    "!wget \"http://dl.fbaipublicfiles.com/m2m_100/language_pairs_small_models.txt\"\n",
    "!wget \"https://dl.fbaipublicfiles.com/m2m_100/418M_last_checkpoint.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import threading \n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASET = \"./\"  #Where you stored the dataset\n",
    "\n",
    "train = pd.read_csv(os.path.join(PATH_TO_DATASET, \"dataset.csv\"))\n",
    "\n",
    "#Remove any possible duplicates\n",
    "train = train.drop_duplicates(subset=[\"korean\", \"english\"])\n",
    "\n",
    "\n",
    "#Lowercase and remove trailing spaces\n",
    "train[\"korean\"] = train.apply(lambda x: (x.korean).strip().lower(), axis=1)\n",
    "#train[\"english\"] = train.english.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "\n",
    "train = train[[\"korean\", \"english\"]]\n",
    "train.columns = [\"input_text\", \"target_text\"]\n",
    "\n",
    "#Train 95% / Validation 5% Split\n",
    "validation = train.sample(frac=0.05).astype(str)\n",
    "train = train.drop(index=validation.index).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = \"\\n\".join(train.input_text.values.tolist())\n",
    "\n",
    "file = open(\"korean_txt_train.txt\", \"w\")\n",
    "file.write(train_txt)\n",
    "file.close()\n",
    "\n",
    "\n",
    "train_target_txt = \"\\n\".join(train.target_text.values.tolist())\n",
    "\n",
    "file = open(\"english_txt_train.txt\", \"w\")\n",
    "file.write(train_target_txt)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28921c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_txt = \"\\n\".join(validation.input_text.values.tolist())\n",
    "\n",
    "file = open(\"korean_txt_validation.txt\", \"w\")\n",
    "file.write(validation_txt)\n",
    "file.close()\n",
    "\n",
    "\n",
    "validation_target_txt = \"\\n\".join(validation.target_text.values.tolist())\n",
    "\n",
    "file = open(\"english_txt_validation.txt\", \"w\")\n",
    "file.write(validation_target_txt)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26285ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/scripts/spm_encode.py \\\n",
    "        --model spm.128k.model \\\n",
    "        --output_format=piece \\\n",
    "        --inputs=korean_txt_train.txt \\\n",
    "        --outputs=train.ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/scripts/spm_encode.py \\\n",
    "        --model spm.128k.model \\\n",
    "        --output_format=piece \\\n",
    "        --inputs=english_txt_train.txt \\\n",
    "        --outputs=train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/scripts/spm_encode.py \\\n",
    "        --model spm.128k.model \\\n",
    "        --output_format=piece \\\n",
    "        --inputs=korean_txt_validation.txt \\\n",
    "        --outputs=val.ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1180ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/scripts/spm_encode.py \\\n",
    "        --model spm.128k.model \\\n",
    "        --output_format=piece \\\n",
    "        --inputs=english_txt_validation.txt \\\n",
    "        --outputs=val.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang ko --target-lang en \\\n",
    "    --trainpref train \\\n",
    "    --validpref val \\\n",
    "    --thresholdsrc 0 --thresholdtgt 0 \\\n",
    "    --destdir data_bin \\\n",
    "    --srcdict model_dict.128k.txt --tgtdict model_dict.128k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_checkpoints():\n",
    "    threading.Timer(5, remove_checkpoints).start()\n",
    "    files = os.listdir(\"checkpoint\")\n",
    "    #print(\"here\")\n",
    "  \n",
    "    for file in files:\n",
    "        if file != \"checkpoint_best.pt\" and file.split(\".\")[-1] ==\"pt\":\n",
    "            #os.remove(\"checkpoint/\"+file)\n",
    "            print(\"X Removed \" + file)\n",
    "\n",
    "remove_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21945f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-train data_bin \\\n",
    "  --finetune-from-model  \"418M_last_checkpoint.pt\"\\\n",
    "  --save-dir checkpoint \\\n",
    "  --task translation_multi_simple_epoch \\\n",
    "  --encoder-normalize-before \\\n",
    "  --lang-pairs 'ko-en' \\\n",
    "  --batch-size 10 \\\n",
    "  --decoder-normalize-before \\\n",
    "  --encoder-langtok src \\\n",
    "  --decoder-langtok \\\n",
    "  --criterion cross_entropy \\\n",
    "  --optimizer adafactor \\\n",
    "  --lr-scheduler cosine \\\n",
    "  --lr 3e-05 \\\n",
    "  --max-update 40000 \\\n",
    "  --update-freq 2 \\\n",
    "  --save-interval 1 \\\n",
    "  --save-interval-updates 5000 \\\n",
    "  --keep-interval-updates 10 \\\n",
    "  --no-epoch-checkpoints \\\n",
    "  --log-format simple \\\n",
    "  --log-interval 2 \\\n",
    "  --patience 10 \\\n",
    "  --arch transformer_wmt_en_de_big \\\n",
    "  --encoder-layers 12 --decoder-layers 12 \\\n",
    "  --share-decoder-input-output-embed --share-all-embeddings \\\n",
    "  --ddp-backend no_c10d \\\n",
    "  --max-epoch 10 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
